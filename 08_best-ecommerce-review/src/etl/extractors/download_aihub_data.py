"""
AI Hub í•œêµ­ì–´ ì‡¼í•‘ ë¦¬ë·° ë°ì´í„° ë‹¤ìš´ë¡œë“œ
ìµœê³  í’ˆì§ˆì˜ í•œêµ­ì–´ ì´ì»¤ë¨¸ìŠ¤ ë¦¬ë·° ë°ì´í„°

ë°ì´í„°ì…‹ ì •ë³´:
- ì¶œì²˜: AI Hub (í•œêµ­ì§€ëŠ¥ì •ë³´ì‚¬íšŒì§„í¥ì›)
- ê·œëª¨: 10ë§Œ~100ë§Œ ê±´
- ì–¸ì–´: í•œêµ­ì–´
- í’ˆì§ˆ: ë†’ìŒ (ê²€ì¦ë¨)
- ë¼ì´ì„ ìŠ¤: ê³µê³µëˆ„ë¦¬ (ì—°êµ¬/ìƒì—… ê°€ëŠ¥)

ì£¼ìš” ë°ì´í„°ì…‹:
1. ì‡¼í•‘ ë¦¬ë·° ê°ì„± ë¶„ì„ ë°ì´í„°
2. ì˜¨ë¼ì¸ ì‡¼í•‘ ìƒí’ˆí‰ ë°ì´í„°
3. ì†Œë¹„ì ë¦¬ë·° ë°ì´í„°
"""

import os
import requests
import zipfile
from pathlib import Path
import pandas as pd
import json

# AI Hub ì£¼ìš” ì‡¼í•‘ ë¦¬ë·° ë°ì´í„°ì…‹
AIHUB_DATASETS = {
    'ì‡¼í•‘_ë¦¬ë·°_ê°ì„±ë¶„ì„': {
        'id': '71',
        'name': 'ì‡¼í•‘ ë¦¬ë·° ê°ì„± ë¶„ì„ ë°ì´í„°',
        'size': 'ì•½ 100ë§Œ ê±´',
        'url': 'https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=71',
        'description': 'ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ìƒí’ˆ ë¦¬ë·° + ê°ì„± ë¼ë²¨',
    },
    'ì‡¼í•‘ëª°_ìƒí’ˆí‰': {
        'id': '96',
        'name': 'ì˜¨ë¼ì¸ ì‡¼í•‘ ìƒí’ˆí‰ ë°ì´í„°',
        'size': 'ì•½ 50ë§Œ ê±´',
        'url': 'https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=96',
        'description': 'ì¹´í…Œê³ ë¦¬ë³„ ìƒí’ˆí‰ + í‰ì ',
    }
}


def print_aihub_guide():
    """AI Hub ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ ì¶œë ¥"""
    
    print("=" * 70)
    print("ğŸ“š AI Hub í•œêµ­ì–´ ì‡¼í•‘ ë¦¬ë·° ë°ì´í„° ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ")
    print("=" * 70)
    print()
    
    print("ğŸ¯ ì¶”ì²œ ë°ì´í„°ì…‹:\n")
    for key, info in AIHUB_DATASETS.items():
        print(f"ğŸ“¦ {info['name']}")
        print(f"   - ID: {info['id']}")
        print(f"   - ê·œëª¨: {info['size']}")
        print(f"   - ì„¤ëª…: {info['description']}")
        print(f"   - URL: {info['url']}")
        print()
    
    print("=" * 70)
    print("ğŸ“¥ ë‹¤ìš´ë¡œë“œ ë°©ë²• (ìˆ˜ë™)")
    print("=" * 70)
    print()
    print("1ï¸âƒ£ AI Hub íšŒì›ê°€ì…")
    print("   https://aihub.or.kr/join/join.do")
    print("   â†’ ë¬´ë£Œ íšŒì›ê°€ì… (1ë¶„)")
    print()
    print("2ï¸âƒ£ ë¡œê·¸ì¸ í›„ ë°ì´í„°ì…‹ í˜ì´ì§€ ì ‘ì†")
    print("   ìœ„ì˜ URL ì¤‘ í•˜ë‚˜ ì„ íƒ")
    print()
    print("3ï¸âƒ£ ë°ì´í„° ì‹ ì²­")
    print("   [ë°ì´í„° ì‹ ì²­] ë²„íŠ¼ í´ë¦­")
    print("   â†’ ì‚¬ìš© ëª©ì  ì…ë ¥ (ì˜ˆ: ê°œì¸ ì—°êµ¬ í”„ë¡œì íŠ¸)")
    print("   â†’ ì‹ ì²­ ì™„ë£Œ (ì¦‰ì‹œ ìŠ¹ì¸)")
    print()
    print("4ï¸âƒ£ ë‹¤ìš´ë¡œë“œ")
    print("   [ë‹¤ìš´ë¡œë“œ] íƒ­ í´ë¦­")
    print("   â†’ Training/Validation ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
    print("   â†’ ZIP íŒŒì¼ ì €ì¥")
    print()
    print("5ï¸âƒ£ ì••ì¶• í•´ì œ")
    print("   â†’ data\\bronze\\aihub\\ í´ë”ì— ì••ì¶• í•´ì œ")
    print()
    print("=" * 70)
    print("âš¡ ë¹ ë¥¸ ëŒ€ì•ˆ: ê³µê³µë°ì´í„°í¬í„¸")
    print("=" * 70)
    print()
    print("AI Hub ìŠ¹ì¸ ëŒ€ê¸° ì‹œê°„ì´ ê¸¸ ê²½ìš°:")
    print("https://www.data.go.kr")
    print("â†’ 'ì‡¼í•‘ ë¦¬ë·°' ë˜ëŠ” 'ìƒí’ˆí‰' ê²€ìƒ‰")
    print("â†’ CSV/JSON í˜•ì‹ ë°ì´í„° ì¦‰ì‹œ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥")
    print()


def extract_aihub_zip(zip_path, output_dir='data/bronze/aihub'):
    """AI Hub ZIP íŒŒì¼ ì••ì¶• í•´ì œ"""
    
    print(f"\nğŸ“¦ ì••ì¶• í•´ì œ ì¤‘: {zip_path}")
    
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(output_dir)
        
        print(f"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ: {output_dir}")
        
        # ì••ì¶• í•´ì œëœ íŒŒì¼ ëª©ë¡
        files = list(Path(output_dir).rglob('*.json')) + list(Path(output_dir).rglob('*.csv'))
        
        print(f"\nğŸ“„ ë°œê²¬ëœ íŒŒì¼ ({len(files)}ê°œ):")
        for f in files[:10]:  # ì²˜ìŒ 10ê°œë§Œ
            print(f"   - {f.name}")
        
        if len(files) > 10:
            print(f"   ... ì™¸ {len(files) - 10}ê°œ")
        
        return files
        
    except Exception as e:
        print(f"âŒ ì••ì¶• í•´ì œ ì‹¤íŒ¨: {e}")
        return []


def convert_aihub_to_standard(input_file, output_csv='data/bronze/aihub/reviews_aihub.csv'):
    """
    AI Hub JSON/CSVë¥¼ í”„ë¡œì íŠ¸ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    
    AI Hub ì¼ë°˜ì ì¸ êµ¬ì¡°:
    {
        "id": "...",
        "review": "ë°°ì†¡ì´ ë¹¨ë¼ìš”",
        "rating": 5,
        "category": "íŒ¨ì…˜",
        "sentiment": "positive",
        ...
    }
    """
    
    print(f"\nğŸ”„ ë°ì´í„° ë³€í™˜ ì¤‘: {input_file}")
    
    file_ext = Path(input_file).suffix.lower()
    
    try:
        # íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ì½ê¸°
        if file_ext == '.json':
            # JSON Lines ë˜ëŠ” ì¼ë°˜ JSON
            try:
                # JSON Lines ì‹œë„
                df = pd.read_json(input_file, lines=True)
            except:
                # ì¼ë°˜ JSON ì‹œë„
                with open(input_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, dict):
                        # {"data": [...]} êµ¬ì¡°
                        df = pd.DataFrame(data.get('data', []))
                    else:
                        df = pd.DataFrame(data)
        
        elif file_ext == '.csv':
            df = pd.read_csv(input_file, encoding='utf-8-sig')
        
        else:
            print(f"âš ï¸  ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
            return None
        
        print(f"âœ… íŒŒì¼ ì½ê¸° ì™„ë£Œ: {len(df):,}ê°œ")
        
        # ì»¬ëŸ¼ ìë™ ë§¤í•‘ (ìœ ì—°í•˜ê²Œ)
        column_mapping = {}
        
        for col in df.columns:
            col_lower = col.lower()
            
            # ë¦¬ë·° ë‚´ìš©
            if any(x in col_lower for x in ['review', 'ë¦¬ë·°', 'ë‚´ìš©', 'content', 'text', 'comment']):
                column_mapping['review_content'] = col
            
            # í‰ì 
            elif any(x in col_lower for x in ['rating', 'í‰ì ', 'score', 'star', 'ë³„ì ']):
                column_mapping['rating'] = col
            
            # ì¹´í…Œê³ ë¦¬
            elif any(x in col_lower for x in ['category', 'ì¹´í…Œê³ ë¦¬', 'type', 'ë¶„ë¥˜']):
                column_mapping['product_category'] = col
            
            # ë‚ ì§œ
            elif any(x in col_lower for x in ['date', 'ë‚ ì§œ', 'ì¼ì', 'time', 'created']):
                column_mapping['created_date'] = col
        
        # í”„ë¡œì íŠ¸ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        df_converted = pd.DataFrame({
            'review_id': [f"AIHUB_{i:08d}" for i in range(len(df))],
            'source': 'aihub',
            'created_date': df[column_mapping.get('created_date', df.columns[0])].iloc[:len(df)] if 'created_date' in column_mapping else pd.Timestamp.now().date(),
            'review_content': df[column_mapping.get('review_content', df.columns[0])],
            'rating': df[column_mapping.get('rating')] if 'rating' in column_mapping else 5.0,
            'author_masked': 'ìµëª…',
            'product_category': df[column_mapping.get('product_category')] if 'product_category' in column_mapping else 'ê¸°íƒ€',
        })
        
        # ë°ì´í„° ì •ì œ
        df_converted = df_converted.dropna(subset=['review_content'])
        df_converted = df_converted[df_converted['review_content'].str.len() >= 5]
        
        # ì €ì¥
        Path(output_csv).parent.mkdir(parents=True, exist_ok=True)
        df_converted.to_csv(output_csv, index=False, encoding='utf-8-sig')
        
        print(f"âœ… ë³€í™˜ ì™„ë£Œ!")
        print(f"   - ì›ë³¸: {len(df):,}ê°œ")
        print(f"   - ë³€í™˜ í›„: {len(df_converted):,}ê°œ")
        print(f"   - ì €ì¥: {output_csv}")
        
        # ìƒ˜í”Œ ì¶œë ¥
        print(f"\nğŸ“‹ ìƒ˜í”Œ ë°ì´í„°:")
        print(df_converted.head(3)[['review_content', 'rating', 'product_category']])
        
        # í†µê³„
        print(f"\nğŸ“Š í†µê³„:")
        print(f"   í‰ê·  í‰ì : {df_converted['rating'].mean():.2f}")
        print(f"   í‰ê·  ê¸¸ì´: {df_converted['review_content'].str.len().mean():.1f}ì")
        
        return output_csv
        
    except Exception as e:
        print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    
    print_aihub_guide()
    
    print("=" * 70)
    print("ğŸ”§ ë³€í™˜ ë„êµ¬")
    print("=" * 70)
    print()
    print("ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ì´ ìˆìœ¼ë©´ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
    print()
    
    while True:
        file_path = input("íŒŒì¼ ê²½ë¡œ ì…ë ¥ (ì¢…ë£Œ: q): ").strip()
        
        if file_path.lower() == 'q':
            break
        
        if not file_path:
            continue
        
        if not Path(file_path).exists():
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\n")
            continue
        
        # ZIP íŒŒì¼ì¸ ê²½ìš° ì••ì¶• í•´ì œ
        if file_path.endswith('.zip'):
            extracted_files = extract_aihub_zip(file_path)
            if extracted_files:
                print("\në³€í™˜í•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:")
                for i, f in enumerate(extracted_files[:10], 1):
                    print(f"  {i}. {f.name}")
                
                try:
                    choice = int(input("\në²ˆí˜¸ ì„ íƒ: "))
                    file_path = extracted_files[choice - 1]
                except:
                    print("âŒ ì˜ëª»ëœ ì„ íƒ")
                    continue
        
        # ë³€í™˜
        output = convert_aihub_to_standard(file_path)
        
        if output:
            print(f"\nâœ… ë³€í™˜ ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„:")
            print(f"   python src/etl/extractors/validate_smartstore_csv.py")
            print(f"   â†’ ê²½ë¡œ: {output}")
        
        print()


if __name__ == "__main__":
    main()
